---
title: "Main File for t2 CAM study (samples from USA, Germany)"
author: "Julius Fenn"
format:
  html:
    toc: true
    toc-depth: 3
    html-math-method: katex
---

```{r}
#| echo: false
#| warning: false
#| results: hide
#| 
# sets the directory of location of this script as the current directory
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))

########################################
# load packages
########################################
require(pacman)
p_load('tidyverse', 'jsonlite', 'magrittr', 'xlsx',
       'stargazer', 'psych', 'jtools', 'DT', 'ggstatsplot', 
       'lavaan', 
       'regsem', 'MplusAutomation', 'igraph')

########################################
# list data files
########################################
setwd("data/Germany")
folders <- list.files(pattern = "^study_result.*")

########################################
# create data files - GERMANY
########################################
### get CAM data
writeLines("", "CAMdata_Germany.txt") # create file
text_connection <- file("CAMdata_Germany.txt", "a") # open connection to append

### get pre CAM data
writeLines("", "preCAM_Germany.txt") # create file
text_connection_pre <- file("preCAM_Germany.txt", "a") # open connection to append

### get post CAM data
writeLines("", "postCAM_Germany.txt") # create file
text_connection_post <- file("postCAM_Germany.txt", "a") # open connection to append

for(i in 1:length(folders)){
  setwd(folders[i])
  if(length(dir()) == 3){
    # print(i)
    ### CAM data
    setwd(dir()[2])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection)
    setwd("..")

    ### pre CAM data
    setwd(dir()[1])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_pre)
    setwd("..")

    ### post CAM data
    setwd(dir()[3])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_post)
    setwd("..")
  }
  setwd("..")
}
close(text_connection) # close connection
close(text_connection_pre) # close connection
close(text_connection_post) # close connection

########################################
# move files to output folder
########################################
### copy files (not overwritten)
tmp_file_from <-  getwd()
setwd("../../outputs")
file.copy(from =  paste0(tmp_file_from, "/CAMdata_Germany.txt"), to = paste0(getwd(), "/CAMdata_Germany.txt"))
file.copy(from =  paste0(tmp_file_from, "/preCAM_Germany.txt"), to = paste0(getwd(), "/preCAM_Germany.txt"))
file.copy(from =  paste0(tmp_file_from, "/postCAM_Germany.txt"), to = paste0(getwd(), "/postCAM_Germany.txt"))
### remove files
file.remove(paste0(tmp_file_from, "/CAMdata_Germany.txt"))
file.remove(paste0(tmp_file_from, "/preCAM_Germany.txt"))
file.remove(paste0(tmp_file_from, "/postCAM_Germany.txt"))



########################################
# list data files - USA
########################################
setwd("../data/USA")
folders <- list.files(pattern = "^study_result.*")

########################################
# create data files
########################################
### get CAM data
writeLines("", "CAMdata_USA.txt") # create file
text_connection <- file("CAMdata_USA.txt", "a") # open connection to append

### get pre CAM data
writeLines("", "preCAM_USA.txt") # create file
text_connection_pre <- file("preCAM_USA.txt", "a") # open connection to append

### get post CAM data
writeLines("", "postCAM_USA.txt") # create file
text_connection_post <- file("postCAM_USA.txt", "a") # open connection to append

for(i in 1:length(folders)){
  setwd(folders[i])
  if(length(dir()) == 3){
    # print(i)
    ### CAM data
    setwd(dir()[2])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection)
    setwd("..")

    ### pre CAM data
    setwd(dir()[1])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_pre)
    setwd("..")

    ### post CAM data
    setwd(dir()[3])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_post)
    setwd("..")
  }
  setwd("..")
}
close(text_connection) # close connection
close(text_connection_pre) # close connection
close(text_connection_post) # close connection

########################################
# move files to output folder
########################################
### copy files (not overwritten)
tmp_file_from <-  getwd()
setwd("../../outputs")
file.copy(from =  paste0(tmp_file_from, "/CAMdata_USA.txt"), to = paste0(getwd(), "/CAMdata_USA.txt"))
file.copy(from =  paste0(tmp_file_from, "/preCAM_USA.txt"), to = paste0(getwd(), "/preCAM_USA.txt"))
file.copy(from =  paste0(tmp_file_from, "/postCAM_USA.txt"), to = paste0(getwd(), "/postCAM_USA.txt"))
### remove files
file.remove(paste0(tmp_file_from, "/CAMdata_USA.txt"))
file.remove(paste0(tmp_file_from, "/preCAM_USA.txt"))
file.remove(paste0(tmp_file_from, "/postCAM_USA.txt"))

########################################
# load functions
########################################
# print(getwd())
setwd("../../../functions")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}


setwd("../functions_CAMapp")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}
rm(i)
```

# Notes

Remark: 

# prepare data

## set up data.frame questionnaires

### for Germany

```{r}
setwd("outputs")
########################################
# Germany
########################################
# > pre study
suppressMessages(read_file('preCAM_Germany.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') %>%
                   # ... parse JSON into a data.frame
                   map_dfr(fromJSON, flatten=TRUE)) -> dat_preCAM_Germany
# > post study
suppressMessages(read_file('postCAM_Germany.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') %>%
                   # ... parse JSON into a data.frame
                   map_dfr(fromJSON, flatten=TRUE)) -> dat_postCAM_Germany


########################################
# create counter variable for both data sets
########################################
### pre study
dat_preCAM_Germany$ID <- NA
dat_preCAM_Germany$country <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_preCAM_Germany)){
  if(!is.na(dat_preCAM_Germany$sender[i]) && dat_preCAM_Germany$sender[i] == "Greetings"){
    # tmp <- dat_preCAM_Germany$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
    dat_preCAM_Germany$country[i] <- "Germany" ## add country
  }
  dat_preCAM_Germany$ID[i] <- tmp_IDcounter
}

### post study
dat_postCAM_Germany$ID <- NA
dat_postCAM_Germany$country <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_postCAM_Germany)){
  if(!is.na(dat_postCAM_Germany$sender[i]) && dat_postCAM_Germany$sender[i] == "CAMfeedbackGeneral"){
    # tmp <- dat_postCAM_Germany$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
    dat_postCAM_Germany$country[i] <- "Germany" ## add country
  }
  dat_postCAM_Germany$ID[i] <- tmp_IDcounter
}


########################################
# keep only complete data sets
########################################
### pre-study
sum(table(dat_preCAM_Germany$ID) != max(table(dat_preCAM_Germany$ID)))
sum(table(dat_preCAM_Germany$ID) == max(table(dat_preCAM_Germany$ID)))

dat_preCAM_Germany <- dat_preCAM_Germany[dat_preCAM_Germany$ID %in% names(table(dat_preCAM_Germany$ID))[table(dat_preCAM_Germany$ID) == max(table(dat_preCAM_Germany$ID))],]

### post-study
sum(table(dat_postCAM_Germany$ID) != max(table(dat_postCAM_Germany$ID)))
sum(table(dat_postCAM_Germany$ID) == max(table(dat_postCAM_Germany$ID)))

dat_postCAM_Germany <- dat_postCAM_Germany[dat_postCAM_Germany$ID %in% names(table(dat_postCAM_Germany$ID))[table(dat_postCAM_Germany$ID) == max(table(dat_postCAM_Germany$ID))],]


########################################
# json (from JATOS) to 2D data.frame
########################################
################################ pre-study
tmp_notNumeric <- str_subset(string = colnames(dat_preCAM_Germany), pattern = "^meta|^R")
tmp_notNumeric <- str_subset(string = tmp_notNumeric, pattern = "labjs|location", negate = TRUE)


vec_ques <- c("PROLIFIC_PID",
                "dummy_informedconsent",
                "commCheck",
                "country",  tmp_notNumeric)

vec_notNumeric = c("PROLIFIC_PID",
                   "country",
                   tmp_notNumeric)

questionnaire_preCAM_Germany <- questionnairetype(dataset = dat_preCAM_Germany, 
                                        listvars = vec_ques, 
                                        notNumeric = vec_notNumeric)


################################ post-study
tmp_numeric <- str_subset(string = colnames(dat_postCAM_Germany), pattern = "^Biospheric|^probabilityClimate|^concernClimate|^Risk|^policyItems")


vec_ques <- c("PROLIFIC_PID",
                tmp_numeric,
                "education",
              "lrscale", "rlgdgr",
                "feedback_critic",
                "country")

vec_notNumeric = c("PROLIFIC_PID",
                   "education",
                   "lrscale", "rlgdgr",
                   "feedback_critic",
                   "country")

questionnaire_postCAM_Germany <- questionnairetype(dataset = dat_postCAM_Germany, 
                                        listvars = vec_ques, 
                                        notNumeric = vec_notNumeric)





################################ post-study CET 
questionnaire_postCAM_Germany$mean_CET <- NA

#> simple mean score
tmp <- dat_postCAM_Germany[, c("ID", "CE_A", "CM_A", "BP_A", "choosenOption")]
# head(tmp)
for(i in 1:length(unique(tmp$ID))){
  tmp_person <- tmp[tmp$ID == unique(tmp$ID)[i], ]
  
  
  questionnaire_postCAM_Germany$mean_CET[questionnaire_postCAM_Germany$ID == unique(tmp$ID)[i]] <- sum(tmp_person$choosenOption == "optionA", na.rm = TRUE) / 25
}


dim(questionnaire_preCAM_Germany)
dim(questionnaire_postCAM_Germany)

questionnaire_Germany <- left_join(questionnaire_preCAM_Germany, questionnaire_postCAM_Germany, by="ID")
dim(questionnaire_Germany)
```

### for USA

```{r}
setwd("outputs")
########################################
# USA
########################################
# > pre study
suppressMessages(read_file('preCAM_USA.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') %>%
                   # ... parse JSON into a data.frame
                   map_dfr(fromJSON, flatten=TRUE)) -> dat_preCAM_USA
# > post study
suppressMessages(read_file('postCAM_USA.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') %>%
                   # ... parse JSON into a data.frame
                   map_dfr(fromJSON, flatten=TRUE)) -> dat_postCAM_USA


########################################
# create counter variable for both data sets
########################################
### pre study
dat_preCAM_USA$ID <- NA
dat_preCAM_USA$country <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_preCAM_USA)){
  if(!is.na(dat_preCAM_USA$sender[i]) && dat_preCAM_USA$sender[i] == "Greetings"){
    # tmp <- dat_preCAM_USA$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
    dat_preCAM_USA$country[i] <- "USA" ## add country
  }
  dat_preCAM_USA$ID[i] <- tmp_IDcounter
}

### post study
dat_postCAM_USA$ID <- NA
dat_postCAM_USA$country <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_postCAM_USA)){
  if(!is.na(dat_postCAM_USA$sender[i]) && dat_postCAM_USA$sender[i] == "CAMfeedbackGeneral"){
    # tmp <- dat_postCAM_USA$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
    dat_postCAM_USA$country[i] <- "USA" ## add country
  }
  dat_postCAM_USA$ID[i] <- tmp_IDcounter
}


########################################
# keep only complete data sets
########################################
### pre-study
sum(table(dat_preCAM_USA$ID) != max(table(dat_preCAM_USA$ID)))
sum(table(dat_preCAM_USA$ID) == max(table(dat_preCAM_USA$ID)))

dat_preCAM_USA <- dat_preCAM_USA[dat_preCAM_USA$ID %in% names(table(dat_preCAM_USA$ID))[table(dat_preCAM_USA$ID) == max(table(dat_preCAM_USA$ID))],]

### post-study
sum(table(dat_postCAM_USA$ID) != max(table(dat_postCAM_USA$ID)))
sum(table(dat_postCAM_USA$ID) == max(table(dat_postCAM_USA$ID)))

dat_postCAM_USA <- dat_postCAM_USA[dat_postCAM_USA$ID %in% names(table(dat_postCAM_USA$ID))[table(dat_postCAM_USA$ID) == max(table(dat_postCAM_USA$ID))],]


########################################
# json (from JATOS) to 2D data.frame
########################################
################################ pre-study
tmp_notNumeric <- str_subset(string = colnames(dat_preCAM_USA), pattern = "^meta|^R")
tmp_notNumeric <- str_subset(string = tmp_notNumeric, pattern = "labjs|location", negate = TRUE)


vec_ques <- c("PROLIFIC_PID",
                "dummy_informedconsent",
                "commCheck",
                "country",  tmp_notNumeric)

vec_notNumeric = c("PROLIFIC_PID",
                   "country",
                   tmp_notNumeric)

questionnaire_preCAM_USA <- questionnairetype(dataset = dat_preCAM_USA, 
                                        listvars = vec_ques, 
                                        notNumeric = vec_notNumeric)


################################ post-study
tmp_numeric <- str_subset(string = colnames(dat_postCAM_USA), pattern = "^Biospheric|^probabilityClimate|^concernClimate|^Risk|^policyItems|rlgdgr")

vec_ques <- c("PROLIFIC_PID",
                tmp_numeric,
                "education",
              "lrscale", "rlgdgr",
                "feedback_critic",
                "country")

vec_notNumeric = c("PROLIFIC_PID",
                   "education",
                   "lrscale", "rlgdgr",
                   "feedback_critic",
                   "country")

questionnaire_postCAM_USA <- questionnairetype(dataset = dat_postCAM_USA, 
                                        listvars = vec_ques, 
                                        notNumeric = vec_notNumeric)


################################ post-study CET 
questionnaire_postCAM_USA$mean_CET <- NA

#> simple mean score
tmp <- dat_postCAM_USA[, c("ID", "CE_A", "CM_A", "BP_A", "choosenOption")]
# head(tmp)
for(i in 1:length(unique(tmp$ID))){
  tmp_person <- tmp[tmp$ID == unique(tmp$ID)[i], ]
  
  
  questionnaire_postCAM_USA$mean_CET[questionnaire_postCAM_USA$ID == unique(tmp$ID)[i]] <- sum(tmp_person$choosenOption == "optionA", na.rm = TRUE) / 25
}


dim(questionnaire_preCAM_USA)
dim(questionnaire_postCAM_USA)

questionnaire_USA <- left_join(questionnaire_preCAM_USA, questionnaire_postCAM_USA, by="ID")
dim(questionnaire_USA)
# questionnaire_USA <- na.omit(questionnaire_USA) # remove 2 missings !!!
# dim(questionnaire_USA)
```

### check current data for conspiracy / country group

```{r}
questionnaire_t1 <- read.xlsx2(file = "data/questionnaire_final.xlsx", sheetIndex = 1)

########################################
# Germany
########################################
tmp_dat <- questionnaire_t1[questionnaire_t1$PROLIFIC_PID %in% questionnaire_Germany$PROLIFIC_PID,]
table(tmp_dat$country)
table(tmp_dat$socio_sex)


tmp_dat$socio_age <- as.numeric(tmp_dat$socio_age)
psych::describe(tmp_dat$socio_age)


table(tmp_dat$classes_conspiracy) # 3 = high, 1 = low


########################################
# USA
########################################
tmp_dat <- questionnaire_t1[questionnaire_t1$PROLIFIC_PID %in% questionnaire_USA$PROLIFIC_PID,]
table(tmp_dat$country)
table(tmp_dat$politicalParty)
table(tmp_dat$socio_sex)

table(tmp_dat$classes_conspiracy) # 3 = high, 1 = low

table(tmp_dat$politicalParty, tmp_dat$classes_conspiracy)

tmp_dat$socio_age <- as.numeric(tmp_dat$socio_age)
psych::describe(tmp_dat$socio_age)

################# IDs who have not participated yet
tmp_dat <- questionnaire_t1[questionnaire_t1$country == "USA" & (questionnaire_t1$classes_conspiracy == "1" | questionnaire_t1$classes_conspiracy == "3"),]
tmp_dat <- tmp_dat$PROLIFIC_PID[!tmp_dat$PROLIFIC_PID %in% questionnaire_USA$PROLIFIC_PID]
write.xlsx2(x = tmp_dat, file = "outputs/PROLIFIC_PIDs_USA_notParticipated.xlsx")
```

## compute mean variables for scales


### for Germany


```{r}
########################################
# number of items for each scale
########################################
sum(str_detect(string = colnames(questionnaire_Germany), pattern = "^Biospheric"))
sum(str_detect(string = colnames(questionnaire_Germany), pattern = "^Risk"))
sum(str_detect(string = colnames(questionnaire_Germany), pattern = "^policyItems"))

sum(str_detect(string = colnames(questionnaire_Germany), pattern = "^concernClimate"))
sum(str_detect(string = colnames(questionnaire_Germany), pattern = "^probabilityClimate"))


########################################
# reverse code all items
#> see negative correlation between single items
########################################

# items van der Linden - Biospheric Values 2015
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^Biospheric")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Biospheric Values scale")

# items van der Linden - Risk Perception 2015
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^Risk")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Risk Perception scale")
# policy items 
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^policyItems")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "policyItems scale")
# items van der Linden - concern climate change
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^concernClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "concern climate change scale")

# items van der Linden - how likely climate change harmful
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^probabilityClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "how likely climate change harmful scale")


# items van der Linden - concern climate change
psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^concernClimate|^probabilityClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "concern climate change plus how likely climate change harmful scale")


########################################
# compute mean variables OVERALL (!)
########################################
### overall mean variables
questionnaire_Germany$mean_BiosphericValues  <- questionnaire_Germany %>%
  select(matches("^Biospheric")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_Germany$mean_RiskPerception  <- questionnaire_Germany %>%
  select(matches("^Risk")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_Germany$mean_PolicyItems  <- questionnaire_Germany %>%
  select(matches("^policyItems")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_Germany$mean_CCCprobability  <- questionnaire_Germany %>%
  select(matches("^concernClimate|^probabilityClimate")) %>%
  rowMeans(na.rm = TRUE)



psych::cor.plot(r = cor(questionnaire_Germany[, str_detect(string = colnames(questionnaire_Germany),
                                                   pattern = "^mean")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "mean scales")
```


### for USA


```{r}
########################################
# number of items for each scale
########################################
sum(str_detect(string = colnames(questionnaire_USA), pattern = "^Biospheric"))
sum(str_detect(string = colnames(questionnaire_USA), pattern = "^Risk"))
sum(str_detect(string = colnames(questionnaire_USA), pattern = "^policyItems"))

sum(str_detect(string = colnames(questionnaire_USA), pattern = "^concernClimate"))
sum(str_detect(string = colnames(questionnaire_USA), pattern = "^probabilityClimate"))


########################################
# reverse code all items
#> see negative correlation between single items
########################################

# items van der Linden - Biospheric Values 2015
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^Biospheric")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Biospheric Values scale")

# items van der Linden - Risk Perception 2015
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^Risk")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Risk Perception scale")
# policy items 
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^policyItems")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "policyItems scale")
# items van der Linden - concern climate change
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^concernClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "concern climate change scale")

# items van der Linden - how likely climate change harmful
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^probabilityClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "how likely climate change harmful scale")


# items van der Linden - concern climate change
psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^concernClimate|^probabilityClimate")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "concern climate change plus how likely climate change harmful scale")


########################################
# compute mean variables OVERALL (!)
########################################
### overall mean variables
questionnaire_USA$mean_BiosphericValues  <- questionnaire_USA %>%
  select(matches("^Biospheric")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_USA$mean_RiskPerception  <- questionnaire_USA %>%
  select(matches("^Risk")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_USA$mean_PolicyItems  <- questionnaire_USA %>%
  select(matches("^policyItems")) %>%
  rowMeans(na.rm = TRUE)

questionnaire_USA$mean_CCCprobability  <- questionnaire_USA %>%
  select(matches("^concernClimate|^probabilityClimate")) %>%
  rowMeans(na.rm = TRUE)



psych::cor.plot(r = cor(questionnaire_USA[, str_detect(string = colnames(questionnaire_USA),
                                                   pattern = "^mean")], 
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "mean scales")
```





## set up CAM data

### for Germany

Load CAM data

```{r, message = FALSE}
setwd("outputs")
suppressMessages(read_file("CAMdata_Germany.txt") %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r')) -> dat_CAM_Germany


raw_CAM_Germany <- list()
for(i in 1:length(dat_CAM_Germany)){
  raw_CAM_Germany[[i]] <- jsonlite::fromJSON(txt = dat_CAM_Germany[[i]])
}
```

Create CAM files, draw CAMs and compute network indicators

```{r, message = FALSE}
########################################
# create CAM single files (nodes, connectors, merged)
########################################
CAMfiles_Germany <- create_CAMfiles(datCAM = raw_CAM_Germany, reDeleted = TRUE)

########################################
# draw CAMs
########################################
CAMdrawn_Germany <- draw_CAM(dat_merged = CAMfiles_Germany[[3]],
                     dat_nodes = CAMfiles_Germany[[1]],ids_CAMs = "all",
                     plot_CAM = FALSE,
                     useCoordinates = TRUE,
                     relvertexsize = 3,
                     reledgesize = 1)

########################################
# draw CAMs
########################################
tmp_microIndicator <- c("Klimawandel")
networkIndicators_Germany <- compute_indicatorsCAM(drawn_CAM = CAMdrawn_Germany, 
                                           micro_degree = tmp_microIndicator, 
                                           micro_valence = tmp_microIndicator, 
                                           micro_centr_clo = tmp_microIndicator, 
                                           micro_transitivity = tmp_microIndicator, 
                                           largestClique = FALSE)


########################################
# wordlists
########################################
CAMwordlist_Germany <- create_wordlist(
  dat_nodes =  CAMfiles_Germany[[1]],
  dat_merged =  CAMfiles_Germany[[3]],
  order = "frequency",
  splitByValence = FALSE,
  comments = TRUE,
  raterSubsetWords = NULL,
  rater = FALSE
)

DT::datatable(CAMwordlist_Germany, options = list(pageLength = 5)) 
```

### translate to English

```{r}
raw_CAM_Germany_translated <- raw_CAM_Germany
CAMfiles_Germany_translated <- CAMfiles_Germany


### load .xlsx with translations
translatedWords <- xlsx::read.xlsx2(file = "data/Deutsche CAMs_Ã¼bersetzt.xlsx", sheetIndex = 2)
translatedWords[158,]
translatedWords <- translatedWords[-158,]
### load protocol
protocol <- rjson::fromJSON(file = "data/protocol_translation.txt")

CAMfiles_Germany_translated[[1]]$text <- str_trim(string = CAMfiles_Germany_translated[[1]]$text, side = "both")

tmp_out <- overwriteTextNodes(protocolDat = protocol,
                                nodesDat = CAMfiles_Germany_translated[[1]])
CAMfiles_Germany_translated[[1]] <- tmp_out[[1]]






for(i in 1:length(raw_CAM_Germany_translated)){
  ## get summarized words
  tmp_nodes <- CAMfiles_Germany_translated[[1]][CAMfiles_Germany_translated[[1]]$CAM == unique(CAMfiles_Germany_translated[[1]]$CAM)[i],]
    tmpWords_summarized <- str_remove_all(string = tmp_nodes$text_summarized, pattern = "_positive$|_negative$|_neutral$|_ambivalent$")
  
  
  if(length(tmpWords_summarized) != sum(raw_CAM_Germany_translated[[i]]$nodes$isActive)){
    print(i)
    print("ERROR")
    break
  }else{
      raw_CAM_Germany_translated[[i]]$nodes$text[raw_CAM_Germany_translated[[i]]$nodes$isActive] <- tmpWords_summarized
  }
  
  ## remove white spaces
  raw_CAM_Germany_translated[[i]]$nodes$text <- str_trim(string = raw_CAM_Germany_translated[[i]]$nodes$text, side = "both")
   
  # tmpWords_raw <- raw_CAM_Germany_translated[[i]]$nodes$text[raw_CAM_Germany_translated[[i]]$nodes$isActive]
  # tmpWords[!tmpWords %in% tmpWords_summarized]
  
  
  tmp <- raw_CAM_Germany_translated[[i]]$nodes$text[raw_CAM_Germany_translated[[i]]$nodes$isActive & !raw_CAM_Germany_translated[[i]]$nodes$text %in% translatedWords$Words]

  if(length(tmp) > 0){
    print(i)
    print(tmp)
    break
  }else{
    
    for(j in 1:length(tmpWords_summarized)){
      # cat("i:", i, "j:", j, "\n")
          raw_CAM_Germany_translated[[i]]$nodes$text[raw_CAM_Germany_translated[[i]]$nodes$isActive][j] <-     translatedWords$Translation[translatedWords$Words %in% tmpWords_summarized[j]]
    }
  }

}




### get CAM data
writeLines("", "outputs/CAMdata_Germany_translated.txt") # create file
text_connection <- file("outputs/CAMdata_Germany_translated.txt", "a") # open connection to append

for(i in 1:length(raw_CAM_Germany_translated)){
      writeLines(jsonlite::toJSON(x = raw_CAM_Germany_translated[[i]], pretty = FALSE, auto_unbox = FALSE), text_connection)

}

close(text_connection) # close connection
```


### save CAMs as .json files, and as .png (igraph)



```{r saveCAMs_pictures_Germany, message = FALSE}
save_CAMs_as_pictures = FALSE

if(save_CAMs_as_pictures){
  setwd("outputs")

setwd("savedCAMs_Germany")
setwd("png")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .png files have been deleted')
}

### if no participant ID was provided replace by randomly generated CAM ID

if(all(CAMfiles_Germany[[3]]$participantCAM.x == "noID")){
  CAMfiles_Germany[[3]]$participantCAM.x <- CAMfiles_Germany[[3]]$CAM.x
}

### save as .json files, and as .png (igraph)
ids_CAMs <- unique(CAMfiles_Germany[[3]]$participantCAM.x); length(ids_CAMs)


for(i in 1:length(ids_CAMs)){
  save_graphic(filename = paste0(ids_CAMs[i]))
  CAM_igraph <- CAMdrawn_Germany[[c(1:length(CAMdrawn_Germany))[
    names(CAMdrawn_Germany) == paste0(unique(CAMfiles_Germany[[3]]$participantCAM.x)[i])]]]
  plot(CAM_igraph, edge.arrow.size = .7,
       layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
       vertex.size = 10, vertex.label.cex = .9)
  dev.off()
}

setwd("../json")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .json files have been deleted')
}
for(i in 1:length(raw_CAM_Germany)){
  if(!is_empty(raw_CAM_Germany[[i]]$nodes)){
    if(nrow(raw_CAM_Germany[[i]]$nodes) > 5){
      write(toJSON(raw_CAM_Germany[[i]], encoding = "UTF-8"),
            paste0(raw_CAM_Germany[[i]]$idCAM, ".json"))
    }
  }
}
}
```


### for USA


```{r, message = FALSE}
setwd("outputs")
suppressMessages(read_file("CAMdata_USA.txt") %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r')) -> dat_CAM_USA

raw_CAM_USA <- list()
for(i in 1:length(dat_CAM_USA)){
  raw_CAM_USA[[i]] <- jsonlite::fromJSON(txt = dat_CAM_USA[[i]])
}
```

Create CAM files, draw CAMs and compute network indicators

```{r, message = FALSE}
########################################
# create CAM single files (nodes, connectors, merged)
########################################
CAMfiles_USA <- create_CAMfiles(datCAM = raw_CAM_USA, reDeleted = TRUE)

########################################
# draw CAMs
########################################
CAMdrawn_USA <- draw_CAM(dat_merged = CAMfiles_USA[[3]],
                     dat_nodes = CAMfiles_USA[[1]],ids_CAMs = "all",
                     plot_CAM = FALSE,
                     useCoordinates = TRUE,
                     relvertexsize = 3,
                     reledgesize = 1)

########################################
# draw CAMs
########################################
tmp_microIndicator <- c("Climate Change")
networkIndicators_USA <- compute_indicatorsCAM(drawn_CAM = CAMdrawn_USA, 
                                           micro_degree = tmp_microIndicator, 
                                           micro_valence = tmp_microIndicator, 
                                           micro_centr_clo = tmp_microIndicator, 
                                           micro_transitivity = tmp_microIndicator, 
                                           largestClique = FALSE)

########################################
# wordlists
########################################
CAMwordlist_USA <- create_wordlist(
  dat_nodes =  CAMfiles_USA[[1]],
  dat_merged =  CAMfiles_USA[[3]],
  order = "frequency",
  splitByValence = FALSE,
  comments = TRUE,
  raterSubsetWords = NULL,
  rater = FALSE
)

DT::datatable(CAMwordlist_USA, options = list(pageLength = 5)) 
```



### save CAMs as .json files, and as .png (igraph)

```{r saveCAMs_pictures_USA, message = FALSE}
save_CAMs_as_pictures = FALSE

if(save_CAMs_as_pictures){
  setwd("outputs")

setwd("savedCAMs_USA")
setwd("png")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .png files have been deleted')
}

### if no participant ID was provided replace by randomly generated CAM ID

if(all(CAMfiles_USA[[3]]$participantCAM.x == "noID")){
  CAMfiles_USA[[3]]$participantCAM.x <- CAMfiles_USA[[3]]$CAM.x
}

### save as .json files, and as .png (igraph)
ids_CAMs <- unique(CAMfiles_USA[[3]]$participantCAM.x); length(ids_CAMs)


for(i in 1:length(ids_CAMs)){
  save_graphic(filename = paste0(ids_CAMs[i]))
  CAM_igraph <- CAMdrawn_USA[[c(1:length(CAMdrawn_USA))[
    names(CAMdrawn_USA) == paste0(unique(CAMfiles_USA[[3]]$participantCAM.x)[i])]]]
  plot(CAM_igraph, edge.arrow.size = .7,
       layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
       vertex.size = 10, vertex.label.cex = .9)
  dev.off()
}

setwd("../json")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .json files have been deleted')
}
for(i in 1:length(raw_CAM_USA)){
  if(!is_empty(raw_CAM_USA[[i]]$nodes)){
    if(nrow(raw_CAM_USA[[i]]$nodes) > 5){
      write(toJSON(raw_CAM_USA[[i]], encoding = "UTF-8"),
            paste0(raw_CAM_USA[[i]]$idCAM, ".json"))
    }
  }
}
}
```



## merge data 

```{r}
dim(questionnaire_Germany)
dim(questionnaire_USA)

## order according to variable names
questionnaire_Germany <- questionnaire_Germany[ , order(names(questionnaire_Germany))]
questionnaire_USA <- questionnaire_USA[ , order(names(questionnaire_USA))]


## add CAM network indicators
questionnaire_CAM_Germany <- cbind(questionnaire_Germany, networkIndicators_Germany)
questionnaire_CAM_Germany$country.x <- NULL
questionnaire_CAM_Germany$country.y <- NULL
questionnaire_CAM_Germany$country <- "Germany"


dim(questionnaire_USA); dim(networkIndicators_USA)
questionnaire_CAM_USA <- cbind(questionnaire_USA, networkIndicators_USA)
questionnaire_CAM_USA$country.x <- NULL
questionnaire_CAM_USA$country.y <- NULL
questionnaire_CAM_USA$country <- "USA"


################# IDs who have participated
tmp_dat <- questionnaire_CAM_USA[, c("PROLIFIC_PID", "ID")]
write.xlsx2(x = tmp_dat, file = "outputs/PROLIFIC_PIDs_USA_Participated.xlsx")


colnames(questionnaire_CAM_Germany)[75:78] <- colnames(questionnaire_CAM_USA)[75:78]

if(all(colnames(questionnaire_CAM_Germany) == colnames(questionnaire_CAM_USA))){
  print("questionnaires, CAM data sets can be merged!")
  questionnaireCAMs <- rbind(questionnaire_CAM_Germany, questionnaire_CAM_USA)
  
  ## save file
  setwd("outputs")
  xlsx::write.xlsx2(x = questionnaireCAMs, file = "questionnaireCAMs.xlsx")
  write.csv2(x = questionnaireCAMs, file = "questionnaireCAMs.csv")
}

```




# analyze data 

## descriptives 

```{r}
table(questionnaireCAMs$country)
```


## correlation plots

### to mean valence

```{r, fig.width=14}
psych::cor.plot(r = cor(questionnaire_CAM_Germany[, str_detect(string = colnames(questionnaire_CAM_Germany),
                                                   pattern = "^mean_")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Germany")


psych::cor.plot(r = cor(questionnaire_CAM_USA[, str_detect(string = colnames(questionnaire_CAM_USA),
                                                   pattern = "^mean_")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "USA")
```


### to number of concepts


```{r, fig.width=14}
psych::cor.plot(r = cor(questionnaire_CAM_Germany[, str_detect(string = colnames(questionnaire_CAM_Germany),
                                                   pattern = "^mean_[:alpha:]*$|^num_nodes")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Germany")


psych::cor.plot(r = cor(questionnaire_CAM_USA[, str_detect(string = colnames(questionnaire_CAM_USA),
                                                   pattern = "^mean_[:alpha:]*$|^num_nodes")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "USA")
```



### to latent parameters


```{r, fig.width=14}
psych::cor.plot(r = cor(questionnaire_CAM_Germany[, str_detect(string = colnames(questionnaire_CAM_Germany),
                                                   pattern = "^mean_[:alpha:]*$|^density|^transitivity.*macro$|^centr.*macro$|^meanDistance|^assortativity.*macro$")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "Germany")


psych::cor.plot(r = cor(questionnaire_CAM_USA[, str_detect(string = colnames(questionnaire_CAM_USA),
                                                   pattern = "^mean_[:alpha:]*$|^density|^transitivity.*macro$|^centr.*macro$|^meanDistance|^assortativity.*macro$")],
                                                   use = "pairwise.complete.obs"),
                                                   upper = FALSE, xlas = 2, main = "USA")
```




## mean differences

```{r}
# questionnaireCAMs$countryParty <- NA
# questionnaireCAMs$CAM_ID %in% questionnaire_t1$PROLIFIC_PID
# questionnaire_t1$politicalParty

ggbetweenstats(
  data = questionnaireCAMs,
  x = country,
  y = mean_valence_macro
)

ggbetweenstats(
  data = questionnaireCAMs,
  x = country,
  y = num_nodes_macro
)

ggbetweenstats(
  data = questionnaireCAMs,
  x = country,
  y = mean_BiosphericValues
)


ggbetweenstats(
  data = questionnaireCAMs,
  x = country,
  y = mean_PolicyItems
)
```

